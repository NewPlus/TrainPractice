task: llm-sft
base_model: meta-llama/Llama-3.2-1B
project_name: llama3-autotrain-ko
log: wandb
backend: local

data:
  path: OLAIR/Open-R1-Ko-SFT-v2.0
  train_split: train
  valid_split: null
  chat_template: tokenizer
  column_mapping:
    prompt_text_column: prompt
    text_column: messages

params:
  block_size: 1024
  model_max_length: 2048
  max_prompt_length: 512
  epochs: 1
  batch_size: 24
  lr: 3e-5
  peft: true
  quantization: int4
  target_modules: all-linear
  padding: right
  optimizer: adamw_torch
  scheduler: linear
  gradient_accumulation: 12
  mixed_precision: bf16
  merge_adapter: true

hub:
  username: NewPlus
  token: ${HF_TOKEN_WRITE}
  push_to_hub: true