# Log - Introduction
- 2025-02-25
- Model: [Llama-3.2-1B](https://huggingface.co/meta-llama/Llama-3.2-1B)
- Dataset: [royboy0416/ko-alpaca](https://huggingface.co/datasets/royboy0416/ko-alpaca)
- AutoTrain

## GPU Usage
- GPU Spec
  - NVIDIA RTX A6000 48GB (x2)
- VRAM Usage: 48GB * 2 = 96GB
- Nvidia-smi(Almost Max Size in Training...)
```bash
Tue Feb 25 12:49:25 2025
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A6000               On  |   00000000:C3:00.0 Off |                  Off |
| 38%   66C    P2            294W /  300W |   48068MiB /  49140MiB |    100%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A6000               On  |   00000000:C4:00.0 Off |                  Off |
| 55%   81C    P2            299W /  300W |   48068MiB /  49140MiB |    100%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
+-----------------------------------------------------------------------------------------+
```

## Training
- epoch: 5
- batch_size: 24
- learning_rate: 3e-5
- lr_scheduler: linear
- optimizer: adamw_torch
- mixed_precision: bf16
- gradient_accumulation: 12
- peft: true
- quantization: int4
- target_modules: all-linear
- padding: right

## Result
- time: 00:36:34
- wandb result
  - [wandb result](https://wandb.ai/newplus/huggingface/runs/yzugjgsa/logs)
- Generation Example
```
안녕하세요<|im_end|>
<|im_start|>assistant
안녕하세요<|
```
- 너무 못 함.
- 데이터가 적은 것(-> 근데 사실 llama-2-7B만 해도 잘 했었음) or 1B 모델이라 그런 듯(* 이게 주요 원인인듯?)
